{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "https://learndatasci.com/tutorials/python-finance-part-yahoo-finance-api-pandas-matplotlib/\n",
    "\n",
    "Resources:\n",
    "* https://github.com/pydata/pandas-datareader\n",
    "* https://h1ros.github.io/posts/getting-real-time-stock-market-data/\n",
    "\n",
    "for future project\n",
    "* https://hackernoon.com/scraping-yahoo-finance-data-using-python-ayu3zyl\n",
    "* https://medium.com/harinathselvaraj/python-code-to-get-realtime-stock-prices-from-yahoo-finance-66d7d1858133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting pandas-datareader\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading pandas_datareader-0.9.0-py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 460 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23 in /home/santos/anaconda3/lib/python3.7/site-packages (from pandas-datareader) (1.0.1)\n",
      "Requirement already satisfied: lxml in /home/santos/anaconda3/lib/python3.7/site-packages (from pandas-datareader) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/santos/anaconda3/lib/python3.7/site-packages (from pandas-datareader) (2.22.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/santos/anaconda3/lib/python3.7/site-packages (from pandas>=0.23->pandas-datareader) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/santos/anaconda3/lib/python3.7/site-packages (from pandas>=0.23->pandas-datareader) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/santos/anaconda3/lib/python3.7/site-packages (from pandas>=0.23->pandas-datareader) (2.8.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader) (2019.11.28)\n",
      "Requirement already satisfied: six>=1.5 in /home/santos/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.23->pandas-datareader) (1.14.0)\n",
      "Installing collected packages: pandas-datareader\n",
      "Successfully installed pandas-datareader-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas-datareader webscrapper\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining wich instruments I want to track. For now I would try only with the mexican index IPC \n",
    "tickers = ['MXX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try with last week data\n",
    "start_date = '2020-07-10'\n",
    "end_date = '2020-07-17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the source\n",
    "source = 'yahoo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fetch the data\n",
    "panel_data = pdr.DataReader('^MXX','yahoo', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-10</th>\n",
       "      <td>36777.769531</td>\n",
       "      <td>36263.968750</td>\n",
       "      <td>36777.769531</td>\n",
       "      <td>36465.460938</td>\n",
       "      <td>105150800</td>\n",
       "      <td>36465.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-13</th>\n",
       "      <td>36939.691406</td>\n",
       "      <td>36321.589844</td>\n",
       "      <td>36602.769531</td>\n",
       "      <td>36389.390625</td>\n",
       "      <td>150410600</td>\n",
       "      <td>36389.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-14</th>\n",
       "      <td>36365.769531</td>\n",
       "      <td>35883.468750</td>\n",
       "      <td>36365.769531</td>\n",
       "      <td>36190.910156</td>\n",
       "      <td>166784200</td>\n",
       "      <td>36190.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-15</th>\n",
       "      <td>36717.531250</td>\n",
       "      <td>36427.839844</td>\n",
       "      <td>36427.839844</td>\n",
       "      <td>36590.261719</td>\n",
       "      <td>194173400</td>\n",
       "      <td>36590.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-16</th>\n",
       "      <td>36533.558594</td>\n",
       "      <td>36193.718750</td>\n",
       "      <td>36517.261719</td>\n",
       "      <td>36465.671875</td>\n",
       "      <td>163886500</td>\n",
       "      <td>36465.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-17</th>\n",
       "      <td>36589.058594</td>\n",
       "      <td>36172.988281</td>\n",
       "      <td>36553.710938</td>\n",
       "      <td>36327.839844</td>\n",
       "      <td>120832098</td>\n",
       "      <td>36327.839844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    High           Low          Open         Close     Volume  \\\n",
       "Date                                                                            \n",
       "2020-07-10  36777.769531  36263.968750  36777.769531  36465.460938  105150800   \n",
       "2020-07-13  36939.691406  36321.589844  36602.769531  36389.390625  150410600   \n",
       "2020-07-14  36365.769531  35883.468750  36365.769531  36190.910156  166784200   \n",
       "2020-07-15  36717.531250  36427.839844  36427.839844  36590.261719  194173400   \n",
       "2020-07-16  36533.558594  36193.718750  36517.261719  36465.671875  163886500   \n",
       "2020-07-17  36589.058594  36172.988281  36553.710938  36327.839844  120832098   \n",
       "\n",
       "               Adj Close  \n",
       "Date                      \n",
       "2020-07-10  36465.460938  \n",
       "2020-07-13  36389.390625  \n",
       "2020-07-14  36190.910156  \n",
       "2020-07-15  36590.261719  \n",
       "2020-07-16  36465.671875  \n",
       "2020-07-17  36327.839844  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the fetched data\n",
    "panel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, this is good, but only works for historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting yahoo_fin\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading yahoo_fin-0.8.6-py3-none-any.whl (8.7 kB)\n",
      "Installing collected packages: yahoo-fin\n",
      "Successfully installed yahoo-fin-0.8.6\n"
     ]
    }
   ],
   "source": [
    "!pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting requests_html\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting parse\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading parse-1.15.0.tar.gz (29 kB)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting w3lib\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in /home/santos/anaconda3/lib/python3.7/site-packages (from requests_html) (2.22.0)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting pyppeteer>=0.0.14\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading pyppeteer-0.2.2-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[?25hCollecting bs4\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting pyquery\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading pyquery-1.4.1-py2.py3-none-any.whl (22 kB)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting fake-useragent\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
      "Requirement already satisfied: six>=1.4.1 in /home/santos/anaconda3/lib/python3.7/site-packages (from w3lib->requests_html) (1.14.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests->requests_html) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests->requests_html) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests->requests_html) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/santos/anaconda3/lib/python3.7/site-packages (from requests->requests_html) (1.25.8)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting appdirs<2.0.0,>=1.4.3\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting pyee<8.0.0,>=7.0.1\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading pyee-7.0.2-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /home/santos/anaconda3/lib/python3.7/site-packages (from pyppeteer>=0.0.14->requests_html) (4.42.1)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting websockets<9.0,>=8.1\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /home/santos/anaconda3/lib/python3.7/site-packages (from bs4->requests_html) (4.8.2)\n",
      "Requirement already satisfied: lxml>=2.1 in /home/santos/anaconda3/lib/python3.7/site-packages (from pyquery->requests_html) (4.5.0)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting cssselect>0.7.9\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/santos/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->bs4->requests_html) (1.9.5)\n",
      "Building wheels for collected packages: parse, bs4, fake-useragent\n",
      "  Building wheel for parse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for parse: filename=parse-1.15.0-py3-none-any.whl size=23709 sha256=cb2b0582e39964e0db595d673a0d8a19710a79123e2106ee503d11aef202e097\n",
      "  Stored in directory: /home/santos/.cache/pip/wheels/d7/b3/1d/5c94c64413b2212f64a297c92f11edd45e4474d08d0220a008\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=02757cbbad54cfc1816a3657366a6141f30beb851e461e20db88e4f45f20f2b8\n",
      "  Stored in directory: /home/santos/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13487 sha256=3f90020731b60b5aaf281ea98e13160437ce4452933a884db87153c49c179af9\n",
      "  Stored in directory: /home/santos/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
      "Successfully built parse bs4 fake-useragent\n",
      "Installing collected packages: parse, w3lib, appdirs, pyee, websockets, pyppeteer, bs4, cssselect, pyquery, fake-useragent, requests-html\n",
      "Successfully installed appdirs-1.4.4 bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.15.0 pyee-7.0.2 pyppeteer-0.2.2 pyquery-1.4.1 requests-html-0.10.0 w3lib-1.22.0 websockets-8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing yahoo_fin lib\n",
    "from yahoo_fin import stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36327.83984375"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_info.get_live_price('^mxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "value =stock_info.get_live_price('^mxx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems to work fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's connect to influx db and save this value at '^mxx-day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting influxdb\n",
      "  Downloading influxdb-5.3.0-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 436 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.17.0 in /opt/conda/lib/python3.8/site-packages (from influxdb) (2.24.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.8/site-packages (from influxdb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from influxdb) (2.8.1)\n",
      "Collecting msgpack==0.6.1\n",
      "  Downloading msgpack-0.6.1.tar.gz (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from influxdb) (2020.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.0->influxdb) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.0->influxdb) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.0->influxdb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.17.0->influxdb) (1.25.9)\n",
      "Building wheels for collected packages: msgpack\n",
      "  Building wheel for msgpack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for msgpack: filename=msgpack-0.6.1-cp38-cp38-linux_x86_64.whl size=343714 sha256=ab74c109c97bb8d20c25a0af652b897853635a6173d0299ddd152a43e1e4d07b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/56/2e/45/9ae160fc31c10e4b799d0ebc32ba82b32f1b057e0ebf28ea82\n",
      "Successfully built msgpack\n",
      "Installing collected packages: msgpack, influxdb\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.0\n",
      "    Uninstalling msgpack-1.0.0:\n",
      "      Successfully uninstalled msgpack-1.0.0\n",
      "Successfully installed influxdb-5.3.0 msgpack-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "from influxdb import exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to InfluxDB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = InfluxDBClient('172.18.0.2', 8086)\n",
    "    client.ping()\n",
    "    print('Connected to InfluxDB')\n",
    "except Exception as e:\n",
    "    print('Connection error: {}'.format(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '_internal'}, {'name': 'testdb'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_list_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.switch_database('testdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from influx db python documentation\n",
    "json_body = [\n",
    "    {\n",
    "        \"measurement\": \"mxx\",\n",
    "        \"tags\": {\n",
    "            \"measurement_type\": \"day\",\n",
    "            \"source\": \"yahoo\"\n",
    "        },\n",
    "        \"time\": '{}'.format(datetime.datetime.now()),\n",
    "        \"fields\": {\n",
    "            \"value\": value\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'measurement': 'mxx',\n",
       "  'tags': {'measurement_type': 'day', 'source': 'yahoo'},\n",
       "  'time': '2020-07-17 18:00:13.389995',\n",
       "  'fields': {'value': 36327.83984375}}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write_points function also can take de different fields as parameters. See documentation.\n",
    "\n",
    "client.write_points(json_body, database='testdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'cpu_load_short'}, {'name': 'mxx'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_list_measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultSet({'('mxx', None)': [{'time': '2020-07-17T18:00:13.389995Z', 'value': 36327.83984375}]})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query(\"Select \\\"value\\\" from mxx where \\\"measurement_type\\\" = 'day'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's wrap all this process together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing yahoo_fin lib\n",
    "from yahoo_fin import stock_info\n",
    "from influxdb import InfluxDBClient\n",
    "from influxdb import exceptions\n",
    "from datetime import datetime\n",
    "\n",
    "# from influx db python documentation\n",
    "json_body = [\n",
    "    {\n",
    "        \"measurement\": \"mxx\",\n",
    "        \"tags\": {\n",
    "            \"measurement_type\": \"day\",\n",
    "            \"source\": \"yahoo\"\n",
    "        },\n",
    "        \"time\": None,\n",
    "        \"fields\": {\n",
    "            \"value\": None\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "tz = pytz.timezone('America/Mexico_City')\n",
    "\n",
    "try:\n",
    "    client = InfluxDBClient('localhost', 8086)\n",
    "    client.ping()\n",
    "    value = stock_info.get_live_price('^mxx')\n",
    "    json_body[0]['time'] = '{}'.format(datetime.now(tz))\n",
    "    json_body[0]['fields']['value'] = value\n",
    "    client.write_points(json_body, database='testdb')\n",
    "except Exception as e:\n",
    "    print('Connection error: {}'.format(str(e)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultSet({'('mxx', None)': [{'time': '2020-07-17T18:00:13.389995Z', 'value': 36327.83984375}, {'time': '2020-07-17T18:35:43.009230Z', 'value': 36327.83984375}, {'time': '2020-07-17T23:40:32.066297Z', 'value': 36327.83984375}]})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query(\"Select \\\"value\\\" from mxx where \\\"measurement_type\\\" = 'day'\", database = 'testdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's create a never ending process here with logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yahoo_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile yahoo_service.py\n",
    "# importing yahoo_fin lib\n",
    "from yahoo_fin import stock_info\n",
    "from influxdb import InfluxDBClient\n",
    "from influxdb import exceptions\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "logging.basicConfig(filename='service.log',level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "# from influx db python documentation\n",
    "json_body = [\n",
    "    {\n",
    "        \"measurement\": \"mxx\",\n",
    "        \"tags\": {\n",
    "            \"measurement_type\": \"day\",\n",
    "            \"source\": \"yahoo\"\n",
    "        },\n",
    "        \"time\": None,\n",
    "        \"fields\": {\n",
    "            \"value\": None\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "tz = pytz.timezone('America/Mexico_City')\n",
    "logging.info('Setting timezone to America/Mexico_City')\n",
    "\n",
    "count=0\n",
    "count_threshold=10\n",
    "try:\n",
    "    logging.info('Connecting to InfluxDB using port 8086...')\n",
    "    client = InfluxDBClient('localhost', 8086)\n",
    "    client.ping()\n",
    "    logging.info('Connected!')\n",
    "    logging.info('Reading stocks value!')\n",
    "    while(True):\n",
    "        value = stock_info.get_live_price('^mxx')\n",
    "        json_body[0]['time'] = '{}'.format(datetime.now(tz))\n",
    "        json_body[0]['fields']['value'] = value\n",
    "        client.write_points(json_body, database='testdb')\n",
    "        time.sleep(1)\n",
    "        count=count+1\n",
    "        if(count==count_threshold):\n",
    "            count = 0 \n",
    "            logging.info('Writing without problems')\n",
    "except Exception as e:\n",
    "    print('Error: {}'.format(str(e)))\n",
    "    logging.error('Service stoped')\n",
    "    logging.error(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Repos/dockers/api_docker_scratch/yahoo_service.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading stocks value...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_live_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^mxx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mjson_body\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mjson_body\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fields'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/yahoo_fin/stock_info.py\u001b[0m in \u001b[0;36mget_live_price\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m    469\u001b[0m     '''    \n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/yahoo_fin/stock_info.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(ticker, start_date, end_date, index_as_date, interval)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# build and connect to URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;34m\"\"\"Closes all adapters and as such the session\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0mcloses\u001b[0m \u001b[0many\u001b[0m \u001b[0mpooled\u001b[0m \u001b[0mconnections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoolmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproxy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mused\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnection_from_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/_collections.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mRequestMethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_pool_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection_pool_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecentlyUsedContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_pools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispose_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Locally set the pool classes and keys so other PoolManagers can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m                     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run -i yahoo_service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I have a raw service to read and write stock data from yahoo API to InfluxDB but it will work 24/7 and I don't want that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. check day is weekday\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is weekend\n"
     ]
    }
   ],
   "source": [
    "weekday = datetime.datetime.now().weekday()\n",
    "if(weekday in [5,6]):\n",
    "    print('Is weekend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check if is in laboral hours:\n",
    "date =  datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working time\n"
     ]
    }
   ],
   "source": [
    "if (9<=date.hour<18):\n",
    "    print('working time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yahoo_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile yahoo_service.py\n",
    "# importing yahoo_fin lib\n",
    "from yahoo_fin import stock_info\n",
    "from influxdb import InfluxDBClient\n",
    "from influxdb import exceptions\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "logging.basicConfig(filename='service.log',level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "# from influx db python documentation\n",
    "\n",
    "tz = pytz.timezone('America/Mexico_City')\n",
    "logging.info('Setting timezone to America/Mexico_City')\n",
    "count=0\n",
    "count_threshold=10\n",
    "try:\n",
    "    logging.info('Connecting to InfluxDB using port 8086...')\n",
    "    client = InfluxDBClient('localhost', 8086)\n",
    "    client.ping()\n",
    "    logging.info('Connected!')\n",
    "    logging.info('Reading stocks value...')\n",
    "    while(True):\n",
    "        if (9<=date.hour<18):\n",
    "            value = stock_info.get_live_price('^mxx')\n",
    "            json_body[0]['time'] = '{}'.format(datetime.now(tz))\n",
    "            json_body[0]['fields']['value'] = value\n",
    "            client.write_points(json_body, database='testdb')\n",
    "            time.sleep(1)\n",
    "            count=count+1\n",
    "            if(count==count_threshold):\n",
    "                count = 0 \n",
    "                logging.info('Writing without problems')\n",
    "        else:\n",
    "            logging.info('BMV finished operations for today.')\n",
    "            logging.info('Closing connections.')\n",
    "            break\n",
    "except Exception as e:\n",
    "    print('Error: {}'.format(str(e)))\n",
    "    logging.error('Service stoped')\n",
    "    logging.error(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "tz = pytz.timezone('America/Mexico_City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.py\n",
    "import logging\n",
    "import pytz\n",
    "\n",
    "log_config={\n",
    "    'log_file_name' : 'yahoo_service.log',\n",
    "    'logging_level' : logging.INFO,\n",
    "    'logging_format' : '%(asctime)s %(message)s' ,\n",
    "}\n",
    "\n",
    "influxdb_config={\n",
    "    \n",
    "    'influxdb_host' : '172.18.0.2', #check the ipv4 from docker network\n",
    "    'influxdb_port' : 8086,\n",
    "    'influxdb_db' : 'testdb',\n",
    "    'influxdb_json_body' : {\n",
    "        \"measurement\": \"mxx\",\n",
    "        \"tags\": {\n",
    "            \"measurement_type\": \"day\",\n",
    "            \"source\": \"yahoo\"\n",
    "        },\n",
    "        \"time\": None,\n",
    "        \"fields\": {\n",
    "            \"value\": None\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "script_config={    \n",
    "    'timezone' : pytz.timezone('America/Mexico_City'),\n",
    "    'script_count_threshold':10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add the config file into the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yahoo_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile yahoo_service.py\n",
    "# importing yahoo_fin lib\n",
    "from influxdb import InfluxDBClient, exceptions\n",
    "from yahoo_fin import stock_info\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import config\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "logging.basicConfig(filename=config.log_config.get('log_file_name'),\n",
    "                    level=config.log_config.get('logging_level'),\n",
    "                    format=config.log_config.get('logging_format')\n",
    "                   )\n",
    "\n",
    "# from influx db python documentation\n",
    "\n",
    "\n",
    "tz = config.script_config.get('timezone')\n",
    "logging.info('Setting timezone to {}'.format(tz.zone))\n",
    "count=0\n",
    "count_threshold=config.script_config.get('script_count_threshold')\n",
    "try:\n",
    "    logging.info('Connecting to InfluxDB using port {}...'.format(config.influxdb_config.get('influxdb_port')))\n",
    "    client = InfluxDBClient(config.influxdb_config.get('influxdb_host'),\n",
    "                            config.influxdb_config.get('influxdb_port')\n",
    "                           )\n",
    "    client.ping()\n",
    "    client.switch_database(config.influxdb_config.get('influxdb_db'))\n",
    "    json_body = [config.influxdb_config.get('influxdb_json_body')]\n",
    "    logging.info('Connected!')\n",
    "    logging.info('Reading stocks value...')\n",
    "    while(True):\n",
    "        if (9<=datetime.now().hour<18):\n",
    "            value = stock_info.get_live_price('^mxx')\n",
    "            json_body[0]['time'] = '{}'.format(datetime.now(tz))\n",
    "            json_body[0]['fields']['value'] = value\n",
    "            client.write_points(json_body)\n",
    "            time.sleep(1)\n",
    "            count=count+1\n",
    "            if(count==count_threshold):\n",
    "                count = 0 \n",
    "                logging.info('Writing without problems')\n",
    "        else:\n",
    "            logging.info('BMV finished operations for today.')\n",
    "            logging.info('Closing connections.')\n",
    "            break\n",
    "except Exception as e:\n",
    "    print('Error: {}'.format(str(e)))\n",
    "    logging.error('Service stoped')\n",
    "    logging.error(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "from yahoo_fin import stock_info\n",
    "from influxdb import exceptions\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import config\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "logging.basicConfig(filename=config.log_config.get('log_file_name'),\n",
    "                    level=config.log_config.get('logging_level'),\n",
    "                    format=config.log_config.get('logging_format')\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = config.script_config.get('timezone')\n",
    "logging.info('Setting timezone to {}'.format(tz.zone))\n",
    "count=0\n",
    "count_threshold=config.script_config.get('script_count_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logging.info('Connecting to InfluxDB using port {}...'.format(config.influxdb_config.get('influxdb_port')))\n",
    "    client = InfluxDBClient(config.influxdb_config.get('influxdb_host'),\n",
    "                            config.influxdb_config.get('influxdb_port')\n",
    "                           )\n",
    "    client.ping()\n",
    "    client.switch_database(config.influxdb_config.get('influxdb_db'))\n",
    "    json_body = [config.influxdb_config.get('influxdb_json_body')]\n",
    "    logging.info('Connected!')\n",
    "    logging.info('Reading stocks value...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'measurement': 'mxx',\n",
       "  'tags': {'measurement_type': 'day', 'source': 'yahoo'},\n",
       "  'time': '2020-07-18 17:35:29.854227-05:00',\n",
       "  'fields': {'value': 36327.83984375}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (9<=datetime.now().hour<18):\n",
    "            value = stock_info.get_live_price('^mxx')\n",
    "            json_body[0]['time'] = '{}'.format(datetime.now(tz))\n",
    "            json_body[0]['fields']['value'] = value\n",
    "            client.write_points(json_body)\n",
    "            time.sleep(1)\n",
    "            count=count+1\n",
    "            if(count==count_threshold):\n",
    "                count = 0 \n",
    "                logging.info('Writing without problems')\n",
    "else:\n",
    "            logging.info('BMV finished operations for today.')\n",
    "            logging.info('Closing connections.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seems to work without problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
